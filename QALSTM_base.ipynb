{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QALSTM_base.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ObvDKDnHhhhooknIKcuPazJuPdXMxjV_",
      "authorship_tag": "ABX9TyM58XyhLVPbQ2wvf3t5OCfC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0Park/QA_LSTM/blob/main/QALSTM_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUE_ae9v0DbH"
      },
      "source": [
        "import pandas as pd\n",
        "QA_df=pd.read_csv('/content/drive/My Drive/QA_LSTM/QA_df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDF_WRqepoV1"
      },
      "source": [
        "dev_QA_df=pd.read_csv('/content/drive/My Drive/QA_LSTM/dev_QA_df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNNqAgtw18KC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "eb0d8adc-bace-4bbc-d766-778498320a40"
      },
      "source": [
        "import gensim\n",
        "model=gensim.models.Word2Vec.load('/content/drive/My Drive/QA_LSTM/KorQuAD.model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4YIdGO12Gkq"
      },
      "source": [
        "question=QA_df['question']\n",
        "answer=QA_df['answer']\n",
        "text=pd.concat([question,answer],axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bej99wa6p8qi"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "max_len=50\n",
        "\n",
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts(text)\n",
        "q_sequences=tokenizer.texts_to_sequences(QA_df['question'])\n",
        "a_sequences=tokenizer.texts_to_sequences(QA_df['answer'])\n",
        "\n",
        "dev_q_sequences=tokenizer.texts_to_sequences(dev_QA_df['question'])\n",
        "dev_a_sequences=tokenizer.texts_to_sequences(dev_QA_df['question'])\n",
        "\n",
        "q_sequences=pad_sequences(q_sequences,maxlen=max_len)\n",
        "a_sequences=pad_sequences(a_sequences,maxlen=max_len)\n",
        "\n",
        "dev_q_sequences=pad_sequences(dev_q_sequences,maxlen=max_len)\n",
        "dev_a_sequences=pad_sequences(dev_a_sequences,maxlen=max_len)\n",
        "word_index=tokenizer.word_index\n",
        "vocab_size=len(word_index)+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGxRvrNM2LAa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "6f74905c-caf0-4269-b04d-1e6db00ac5fe"
      },
      "source": [
        "import numpy as np\n",
        "Embedding_matrix=np.zeros((vocab_size,200))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    word=word.replace(\"'\",\"\")\n",
        "    try:\n",
        "        embedding_vector=model[word]\n",
        "    except KeyError:\n",
        "        continue\n",
        "    Embedding_matrix[i]=embedding_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJBFFSOI2Ocs"
      },
      "source": [
        "an_sequences=np.array(a_sequences)\n",
        "np.random.shuffle(an_sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEc7aN8Trzvd"
      },
      "source": [
        "dev_an_sequences=np.array(dev_a_sequences)\n",
        "np.random.shuffle(dev_an_sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyXR9Rot2VOf"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding,LSTM,Bidirectional,MaxPool1D\n",
        "from tensorflow.keras.layers import Lambda,Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "embedding_dim=200\n",
        "max_len=50\n",
        "hidden_size=50\n",
        "margin=0.2\n",
        "\n",
        "def get_cosine_similarity():\n",
        "    dot=lambda a,b: K.batch_dot(a, b,axes=2)\n",
        "    return lambda x: dot(x[0],x[1])/K.maximum(K.sqrt(dot(x[0],x[0])*dot(x[1],x[1])),K.epsilon())\n",
        "\n",
        "question=Input(shape=(max_len,),dtype='float64',name='question_base')\n",
        "answer=Input(shape=(max_len),dtype='float64',name='answer')\n",
        "answer_good=Input(shape=(max_len),dtype='float64',name='answer_good_base')\n",
        "answer_bad=Input(shape=(max_len,),dtype='float64',name='answer_bad_base')\n",
        "\n",
        "qa_embedding=Embedding(vocab_size,embedding_dim,weights=[Embedding_matrix],input_length=max_len,trainable=True,mask_zero=True)\n",
        "bi_lstm=Bidirectional(LSTM(units=hidden_size,dropout=0.2,return_sequences=True))\n",
        "\n",
        "question_embedding=qa_embedding(question)\n",
        "question_lstm=bi_lstm(question_embedding)\n",
        "question_pooling=MaxPool1D(max_len)(question_lstm)\n",
        "\n",
        "answer_embedding=qa_embedding(answer)\n",
        "answer_lstm=bi_lstm(answer_embedding)\n",
        "answer_pooling=MaxPool1D(max_len)(answer_lstm)\n",
        "\n",
        "similarity=get_cosine_similarity()\n",
        "question_answer_merged=Lambda(similarity,name='lambda_layer')([question_pooling,answer_pooling])\n",
        "lstm_model=Model(name='q_bilstm',inputs=[question,answer],outputs=question_answer_merged)\n",
        "good_similarity=lstm_model([question,answer_good])\n",
        "bad_similarity=lstm_model([question,answer_bad])\n",
        "\n",
        "# compute the loss\n",
        "loss=Lambda(lambda x: K.maximum(0.0,margin-x[0]+x[1]))([good_similarity,bad_similarity])\n",
        "#return training and prediction model\n",
        "\n",
        "training_model=Model(inputs=[question,answer_good,answer_bad],outputs=loss,name='training_model')\n",
        "training_model.compile(loss=lambda y_true,y_pred: y_pred,optimizer=\"rmsprop\")\n",
        "prediction_model=Model(inputs=[question,answer_good],outputs=good_similarity,name='prediction_model')\n",
        "prediction_model.compile(loss=lambda y_true,y_pred: y_pred,optimizer='rmsprop')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBAR5Ba22zLq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "7401a469-cb28-46c0-b8b1-e590b38782f6"
      },
      "source": [
        "Y=np.zeros(shape=(q_sequences.shape[0],))\n",
        "training_model.fit([q_sequences,a_sequences,an_sequences],Y,epochs=2,batch_size=64,validation_split=0.1,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "850/850 [==============================] - 474s 558ms/step - loss: 0.0148 - val_loss: 0.0112\n",
            "Epoch 2/2\n",
            " 54/850 [>.............................] - ETA: 7:05 - loss: 0.0066"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-ce55b833a6de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_sequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq_sequences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma_sequences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0man_sequences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdbnhr_ZyZsa"
      },
      "source": [
        "training_model.save('/content/drive/My Drive/QA_LSTM/training_model3.h5')\n",
        "prediction_model.save('/content/drive/My Drive/QA_LSTM/prediction_model2.h5')\n",
        "training_model.save_weights('/content/drive/My Drive/QA_LSTM/training_weight2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qMrBwAmCY9s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "0114eac0-423d-4d06-9acf-455a40ad69db"
      },
      "source": [
        "training_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"training_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "question_base (InputLayer)      [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "answer_good_base (InputLayer)   [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "answer_bad_base (InputLayer)    [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "q_bilstm (Functional)           (None, 1, 1)         12155800    question_base[0][0]              \n",
            "                                                                 answer_good_base[0][0]           \n",
            "                                                                 question_base[0][0]              \n",
            "                                                                 answer_bad_base[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 1, 1)         0           q_bilstm[0][0]                   \n",
            "                                                                 q_bilstm[1][0]                   \n",
            "==================================================================================================\n",
            "Total params: 12,155,800\n",
            "Trainable params: 12,155,800\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twq4H71NCmwt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "1548ceb3-ba0f-469f-c243-01a6191bd13b"
      },
      "source": [
        "prediction_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"prediction_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "question_base (InputLayer)      [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "answer_good_base (InputLayer)   [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "q_bilstm (Functional)           (None, 1, 1)         12155800    question_base[0][0]              \n",
            "                                                                 answer_good_base[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 12,155,800\n",
            "Trainable params: 12,155,800\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC80WgWcC2QW"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKRX0_cwwSXL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "113e6647-4ec4-437c-a78c-a84f79dc53b5"
      },
      "source": [
        "prediction_model.load_weights('/content/drive/My Drive/QA_LSTM/training_weight2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fe281eb2588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8HoziECwPYO"
      },
      "source": [
        "x_array=np.array([dev_q_sequences[4000] for i in range(dev_q_sequences.shape[0])])\n",
        "sim=prediction_model.predict([x_array,dev_a_sequences])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF5I0wj9wUoo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "3dd0dcb1-0f37-49e7-a593-450744ab4a4e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "sim=sim.reshape(sim.shape[0],-1)\n",
        "plt.plot(sim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe28fce42b0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-evmn8UEC3Bq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f970e3f3-c55f-4316-e62d-ab32d0a38e58"
      },
      "source": [
        "acc=0\n",
        "for j in range(dev_q_sequences.shape[0]):\n",
        "  x_array=np.array([dev_q_sequences[j] for i in range(dev_q_sequences.shape[0])])\n",
        "  sim=prediction_model.predict([x_array,dev_a_sequences])\n",
        "  indice=np.argmax(sim)\n",
        "  print(\"question, answer:\",j,indice)\n",
        "  acc+=1 if j == indice else 0\n",
        "acc=acc/dev_q_sequences.shape[0]\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "question, answer: 0 0\n",
            "question, answer: 1 1\n",
            "question, answer: 2 2\n",
            "question, answer: 3 3\n",
            "question, answer: 4 4\n",
            "question, answer: 5 5\n",
            "question, answer: 6 6\n",
            "question, answer: 7 7\n",
            "question, answer: 8 8\n",
            "question, answer: 9 9\n",
            "question, answer: 10 10\n",
            "question, answer: 11 11\n",
            "question, answer: 12 12\n",
            "question, answer: 13 13\n",
            "question, answer: 14 14\n",
            "question, answer: 15 15\n",
            "question, answer: 16 16\n",
            "question, answer: 17 17\n",
            "question, answer: 18 18\n",
            "question, answer: 19 19\n",
            "question, answer: 20 20\n",
            "question, answer: 21 21\n",
            "question, answer: 22 22\n",
            "question, answer: 23 23\n",
            "question, answer: 24 24\n",
            "question, answer: 25 25\n",
            "question, answer: 26 26\n",
            "question, answer: 27 27\n",
            "question, answer: 28 28\n",
            "question, answer: 29 29\n",
            "question, answer: 30 30\n",
            "question, answer: 31 31\n",
            "question, answer: 32 32\n",
            "question, answer: 33 33\n",
            "question, answer: 34 34\n",
            "question, answer: 35 35\n",
            "question, answer: 36 36\n",
            "question, answer: 37 37\n",
            "question, answer: 38 38\n",
            "question, answer: 39 39\n",
            "question, answer: 40 40\n",
            "question, answer: 41 41\n",
            "question, answer: 42 42\n",
            "question, answer: 43 43\n",
            "question, answer: 44 44\n",
            "question, answer: 45 45\n",
            "question, answer: 46 46\n",
            "question, answer: 47 47\n",
            "question, answer: 48 48\n",
            "question, answer: 49 49\n",
            "question, answer: 50 50\n",
            "question, answer: 51 51\n",
            "question, answer: 52 52\n",
            "question, answer: 53 53\n",
            "question, answer: 54 54\n",
            "question, answer: 55 55\n",
            "question, answer: 56 56\n",
            "question, answer: 57 57\n",
            "question, answer: 58 58\n",
            "question, answer: 59 59\n",
            "question, answer: 60 60\n",
            "question, answer: 61 61\n",
            "question, answer: 62 62\n",
            "question, answer: 63 63\n",
            "question, answer: 64 64\n",
            "question, answer: 65 65\n",
            "question, answer: 66 66\n",
            "question, answer: 67 67\n",
            "question, answer: 68 68\n",
            "question, answer: 69 69\n",
            "question, answer: 70 70\n",
            "question, answer: 71 71\n",
            "question, answer: 72 72\n",
            "question, answer: 73 73\n",
            "question, answer: 74 74\n",
            "question, answer: 75 75\n",
            "question, answer: 76 76\n",
            "question, answer: 77 77\n",
            "question, answer: 78 78\n",
            "question, answer: 79 79\n",
            "question, answer: 80 80\n",
            "question, answer: 81 81\n",
            "question, answer: 82 82\n",
            "question, answer: 83 83\n",
            "question, answer: 84 84\n",
            "question, answer: 85 85\n",
            "question, answer: 86 86\n",
            "question, answer: 87 87\n",
            "question, answer: 88 88\n",
            "question, answer: 89 89\n",
            "question, answer: 90 90\n",
            "question, answer: 91 91\n",
            "question, answer: 92 92\n",
            "question, answer: 93 93\n",
            "question, answer: 94 94\n",
            "question, answer: 95 95\n",
            "question, answer: 96 96\n",
            "question, answer: 97 97\n",
            "question, answer: 98 98\n",
            "question, answer: 99 99\n",
            "question, answer: 100 100\n",
            "question, answer: 101 101\n",
            "question, answer: 102 102\n",
            "question, answer: 103 103\n",
            "question, answer: 104 104\n",
            "question, answer: 105 105\n",
            "question, answer: 106 106\n",
            "question, answer: 107 107\n",
            "question, answer: 108 108\n",
            "question, answer: 109 109\n",
            "question, answer: 110 110\n",
            "question, answer: 111 111\n",
            "question, answer: 112 112\n",
            "question, answer: 113 113\n",
            "question, answer: 114 114\n",
            "question, answer: 115 115\n",
            "question, answer: 116 116\n",
            "question, answer: 117 117\n",
            "question, answer: 118 118\n",
            "question, answer: 119 119\n",
            "question, answer: 120 120\n",
            "question, answer: 121 121\n",
            "question, answer: 122 122\n",
            "question, answer: 123 123\n",
            "question, answer: 124 124\n",
            "question, answer: 125 125\n",
            "question, answer: 126 126\n",
            "question, answer: 127 127\n",
            "question, answer: 128 128\n",
            "question, answer: 129 129\n",
            "question, answer: 130 130\n",
            "question, answer: 131 131\n",
            "question, answer: 132 132\n",
            "question, answer: 133 133\n",
            "question, answer: 134 134\n",
            "question, answer: 135 135\n",
            "question, answer: 136 136\n",
            "question, answer: 137 137\n",
            "question, answer: 138 138\n",
            "question, answer: 139 139\n",
            "question, answer: 140 140\n",
            "question, answer: 141 141\n",
            "question, answer: 142 142\n",
            "question, answer: 143 143\n",
            "question, answer: 144 144\n",
            "question, answer: 145 145\n",
            "question, answer: 146 146\n",
            "question, answer: 147 147\n",
            "question, answer: 148 148\n",
            "question, answer: 149 149\n",
            "question, answer: 150 150\n",
            "question, answer: 151 151\n",
            "question, answer: 152 152\n",
            "question, answer: 153 153\n",
            "question, answer: 154 154\n",
            "question, answer: 155 155\n",
            "question, answer: 156 156\n",
            "question, answer: 157 157\n",
            "question, answer: 158 158\n",
            "question, answer: 159 159\n",
            "question, answer: 160 160\n",
            "question, answer: 161 161\n",
            "question, answer: 162 162\n",
            "question, answer: 163 163\n",
            "question, answer: 164 164\n",
            "question, answer: 165 165\n",
            "question, answer: 166 166\n",
            "question, answer: 167 167\n",
            "question, answer: 168 168\n",
            "question, answer: 169 169\n",
            "question, answer: 170 170\n",
            "question, answer: 171 171\n",
            "question, answer: 172 172\n",
            "question, answer: 173 173\n",
            "question, answer: 174 174\n",
            "question, answer: 175 175\n",
            "question, answer: 176 176\n",
            "question, answer: 177 177\n",
            "question, answer: 178 178\n",
            "question, answer: 179 179\n",
            "question, answer: 180 180\n",
            "question, answer: 181 181\n",
            "question, answer: 182 182\n",
            "question, answer: 183 183\n",
            "question, answer: 184 184\n",
            "question, answer: 185 185\n",
            "question, answer: 186 186\n",
            "question, answer: 187 187\n",
            "question, answer: 188 188\n",
            "question, answer: 189 189\n",
            "question, answer: 190 190\n",
            "question, answer: 191 191\n",
            "question, answer: 192 192\n",
            "question, answer: 193 193\n",
            "question, answer: 194 194\n",
            "question, answer: 195 195\n",
            "question, answer: 196 196\n",
            "question, answer: 197 197\n",
            "question, answer: 198 198\n",
            "question, answer: 199 199\n",
            "question, answer: 200 200\n",
            "question, answer: 201 201\n",
            "question, answer: 202 202\n",
            "question, answer: 203 203\n",
            "question, answer: 204 204\n",
            "question, answer: 205 205\n",
            "question, answer: 206 206\n",
            "question, answer: 207 207\n",
            "question, answer: 208 208\n",
            "question, answer: 209 209\n",
            "question, answer: 210 210\n",
            "question, answer: 211 211\n",
            "question, answer: 212 212\n",
            "question, answer: 213 213\n",
            "question, answer: 214 214\n",
            "question, answer: 215 215\n",
            "question, answer: 216 216\n",
            "question, answer: 217 217\n",
            "question, answer: 218 218\n",
            "question, answer: 219 219\n",
            "question, answer: 220 220\n",
            "question, answer: 221 221\n",
            "question, answer: 222 222\n",
            "question, answer: 223 223\n",
            "question, answer: 224 224\n",
            "question, answer: 225 225\n",
            "question, answer: 226 226\n",
            "question, answer: 227 227\n",
            "question, answer: 228 228\n",
            "question, answer: 229 229\n",
            "question, answer: 230 230\n",
            "question, answer: 231 231\n",
            "question, answer: 232 232\n",
            "question, answer: 233 233\n",
            "question, answer: 234 234\n",
            "question, answer: 235 235\n",
            "question, answer: 236 236\n",
            "question, answer: 237 237\n",
            "question, answer: 238 238\n",
            "question, answer: 239 239\n",
            "question, answer: 240 240\n",
            "question, answer: 241 241\n",
            "question, answer: 242 242\n",
            "question, answer: 243 243\n",
            "question, answer: 244 244\n",
            "question, answer: 245 245\n",
            "question, answer: 246 246\n",
            "question, answer: 247 247\n",
            "question, answer: 248 248\n",
            "question, answer: 249 249\n",
            "question, answer: 250 250\n",
            "question, answer: 251 251\n",
            "question, answer: 252 252\n",
            "question, answer: 253 253\n",
            "question, answer: 254 254\n",
            "question, answer: 255 255\n",
            "question, answer: 256 256\n",
            "question, answer: 257 257\n",
            "question, answer: 258 258\n",
            "question, answer: 259 259\n",
            "question, answer: 260 260\n",
            "question, answer: 261 261\n",
            "question, answer: 262 262\n",
            "question, answer: 263 263\n",
            "question, answer: 264 264\n",
            "question, answer: 265 265\n",
            "question, answer: 266 266\n",
            "question, answer: 267 267\n",
            "question, answer: 268 268\n",
            "question, answer: 269 269\n",
            "question, answer: 270 267\n",
            "question, answer: 271 271\n",
            "question, answer: 272 272\n",
            "question, answer: 273 273\n",
            "question, answer: 274 274\n",
            "question, answer: 275 275\n",
            "question, answer: 276 276\n",
            "question, answer: 277 277\n",
            "question, answer: 278 278\n",
            "question, answer: 279 279\n",
            "question, answer: 280 280\n",
            "question, answer: 281 281\n",
            "question, answer: 282 282\n",
            "question, answer: 283 283\n",
            "question, answer: 284 284\n",
            "question, answer: 285 285\n",
            "question, answer: 286 286\n",
            "question, answer: 287 287\n",
            "question, answer: 288 288\n",
            "question, answer: 289 289\n",
            "question, answer: 290 290\n",
            "question, answer: 291 291\n",
            "question, answer: 292 292\n",
            "question, answer: 293 293\n",
            "question, answer: 294 294\n",
            "question, answer: 295 295\n",
            "question, answer: 296 296\n",
            "question, answer: 297 297\n",
            "question, answer: 298 298\n",
            "question, answer: 299 299\n",
            "question, answer: 300 300\n",
            "question, answer: 301 301\n",
            "question, answer: 302 302\n",
            "question, answer: 303 303\n",
            "question, answer: 304 304\n",
            "question, answer: 305 305\n",
            "question, answer: 306 306\n",
            "question, answer: 307 307\n",
            "question, answer: 308 308\n",
            "question, answer: 309 309\n",
            "question, answer: 310 310\n",
            "question, answer: 311 311\n",
            "question, answer: 312 312\n",
            "question, answer: 313 313\n",
            "question, answer: 314 314\n",
            "question, answer: 315 315\n",
            "question, answer: 316 316\n",
            "question, answer: 317 317\n",
            "question, answer: 318 318\n",
            "question, answer: 319 319\n",
            "question, answer: 320 320\n",
            "question, answer: 321 321\n",
            "question, answer: 322 322\n",
            "question, answer: 323 323\n",
            "question, answer: 324 324\n",
            "question, answer: 325 325\n",
            "question, answer: 326 326\n",
            "question, answer: 327 327\n",
            "question, answer: 328 328\n",
            "question, answer: 329 329\n",
            "question, answer: 330 330\n",
            "question, answer: 331 331\n",
            "question, answer: 332 332\n",
            "question, answer: 333 333\n",
            "question, answer: 334 334\n",
            "question, answer: 335 335\n",
            "question, answer: 336 336\n",
            "question, answer: 337 337\n",
            "question, answer: 338 338\n",
            "question, answer: 339 339\n",
            "question, answer: 340 340\n",
            "question, answer: 341 341\n",
            "question, answer: 342 342\n",
            "question, answer: 343 343\n",
            "question, answer: 344 344\n",
            "question, answer: 345 345\n",
            "question, answer: 346 346\n",
            "question, answer: 347 347\n",
            "question, answer: 348 348\n",
            "question, answer: 349 349\n",
            "question, answer: 350 350\n",
            "question, answer: 351 351\n",
            "question, answer: 352 352\n",
            "question, answer: 353 353\n",
            "question, answer: 354 354\n",
            "question, answer: 355 355\n",
            "question, answer: 356 356\n",
            "question, answer: 357 357\n",
            "question, answer: 358 358\n",
            "question, answer: 359 359\n",
            "question, answer: 360 360\n",
            "question, answer: 361 361\n",
            "question, answer: 362 362\n",
            "question, answer: 363 363\n",
            "question, answer: 364 364\n",
            "question, answer: 365 365\n",
            "question, answer: 366 366\n",
            "question, answer: 367 367\n",
            "question, answer: 368 368\n",
            "question, answer: 369 369\n",
            "question, answer: 370 370\n",
            "question, answer: 371 371\n",
            "question, answer: 372 372\n",
            "question, answer: 373 373\n",
            "question, answer: 374 374\n",
            "question, answer: 375 375\n",
            "question, answer: 376 376\n",
            "question, answer: 377 377\n",
            "question, answer: 378 378\n",
            "question, answer: 379 379\n",
            "question, answer: 380 380\n",
            "question, answer: 381 381\n",
            "question, answer: 382 382\n",
            "question, answer: 383 383\n",
            "question, answer: 384 384\n",
            "question, answer: 385 385\n",
            "question, answer: 386 386\n",
            "question, answer: 387 387\n",
            "question, answer: 388 388\n",
            "question, answer: 389 389\n",
            "question, answer: 390 390\n",
            "question, answer: 391 391\n",
            "question, answer: 392 392\n",
            "question, answer: 393 393\n",
            "question, answer: 394 394\n",
            "question, answer: 395 395\n",
            "question, answer: 396 396\n",
            "question, answer: 397 397\n",
            "question, answer: 398 398\n",
            "question, answer: 399 399\n",
            "question, answer: 400 400\n",
            "question, answer: 401 401\n",
            "question, answer: 402 402\n",
            "question, answer: 403 403\n",
            "question, answer: 404 404\n",
            "question, answer: 405 405\n",
            "question, answer: 406 406\n",
            "question, answer: 407 407\n",
            "question, answer: 408 408\n",
            "question, answer: 409 409\n",
            "question, answer: 410 410\n",
            "question, answer: 411 411\n",
            "question, answer: 412 412\n",
            "question, answer: 413 413\n",
            "question, answer: 414 414\n",
            "question, answer: 415 415\n",
            "question, answer: 416 416\n",
            "question, answer: 417 417\n",
            "question, answer: 418 418\n",
            "question, answer: 419 419\n",
            "question, answer: 420 420\n",
            "question, answer: 421 421\n",
            "question, answer: 422 422\n",
            "question, answer: 423 423\n",
            "question, answer: 424 424\n",
            "question, answer: 425 425\n",
            "question, answer: 426 426\n",
            "question, answer: 427 427\n",
            "question, answer: 428 428\n",
            "question, answer: 429 429\n",
            "question, answer: 430 430\n",
            "question, answer: 431 431\n",
            "question, answer: 432 432\n",
            "question, answer: 433 433\n",
            "question, answer: 434 434\n",
            "question, answer: 435 435\n",
            "question, answer: 436 436\n",
            "question, answer: 437 437\n",
            "question, answer: 438 438\n",
            "question, answer: 439 439\n",
            "question, answer: 440 440\n",
            "question, answer: 441 441\n",
            "question, answer: 442 442\n",
            "question, answer: 443 443\n",
            "question, answer: 444 444\n",
            "question, answer: 445 445\n",
            "question, answer: 446 446\n",
            "question, answer: 447 447\n",
            "question, answer: 448 448\n",
            "question, answer: 449 449\n",
            "question, answer: 450 450\n",
            "question, answer: 451 451\n",
            "question, answer: 452 452\n",
            "question, answer: 453 453\n",
            "question, answer: 454 454\n",
            "question, answer: 455 455\n",
            "question, answer: 456 456\n",
            "question, answer: 457 457\n",
            "question, answer: 458 458\n",
            "question, answer: 459 459\n",
            "question, answer: 460 460\n",
            "question, answer: 461 461\n",
            "question, answer: 462 462\n",
            "question, answer: 463 463\n",
            "question, answer: 464 464\n",
            "question, answer: 465 465\n",
            "question, answer: 466 466\n",
            "question, answer: 467 467\n",
            "question, answer: 468 468\n",
            "question, answer: 469 469\n",
            "question, answer: 470 470\n",
            "question, answer: 471 471\n",
            "question, answer: 472 472\n",
            "question, answer: 473 473\n",
            "question, answer: 474 474\n",
            "question, answer: 475 475\n",
            "question, answer: 476 476\n",
            "question, answer: 477 477\n",
            "question, answer: 478 478\n",
            "question, answer: 479 479\n",
            "question, answer: 480 480\n",
            "question, answer: 481 481\n",
            "question, answer: 482 482\n",
            "question, answer: 483 483\n",
            "question, answer: 484 484\n",
            "question, answer: 485 485\n",
            "question, answer: 486 486\n",
            "question, answer: 487 487\n",
            "question, answer: 488 488\n",
            "question, answer: 489 489\n",
            "question, answer: 490 490\n",
            "question, answer: 491 491\n",
            "question, answer: 492 492\n",
            "question, answer: 493 493\n",
            "question, answer: 494 494\n",
            "question, answer: 495 495\n",
            "question, answer: 496 496\n",
            "question, answer: 497 497\n",
            "question, answer: 498 498\n",
            "question, answer: 499 499\n",
            "question, answer: 500 500\n",
            "question, answer: 501 501\n",
            "question, answer: 502 502\n",
            "question, answer: 503 503\n",
            "question, answer: 504 504\n",
            "question, answer: 505 505\n",
            "question, answer: 506 506\n",
            "question, answer: 507 507\n",
            "question, answer: 508 508\n",
            "question, answer: 509 509\n",
            "question, answer: 510 510\n",
            "question, answer: 511 511\n",
            "question, answer: 512 512\n",
            "question, answer: 513 513\n",
            "question, answer: 514 514\n",
            "question, answer: 515 515\n",
            "question, answer: 516 516\n",
            "question, answer: 517 517\n",
            "question, answer: 518 518\n",
            "question, answer: 519 519\n",
            "question, answer: 520 520\n",
            "question, answer: 521 521\n",
            "question, answer: 522 522\n",
            "question, answer: 523 523\n",
            "question, answer: 524 524\n",
            "question, answer: 525 525\n",
            "question, answer: 526 526\n",
            "question, answer: 527 527\n",
            "question, answer: 528 528\n",
            "question, answer: 529 529\n",
            "question, answer: 530 530\n",
            "question, answer: 531 531\n",
            "question, answer: 532 529\n",
            "question, answer: 533 533\n",
            "question, answer: 534 528\n",
            "question, answer: 535 535\n",
            "question, answer: 536 536\n",
            "question, answer: 537 537\n",
            "question, answer: 538 538\n",
            "question, answer: 539 539\n",
            "question, answer: 540 540\n",
            "question, answer: 541 541\n",
            "question, answer: 542 542\n",
            "question, answer: 543 543\n",
            "question, answer: 544 544\n",
            "question, answer: 545 545\n",
            "question, answer: 546 546\n",
            "question, answer: 547 547\n",
            "question, answer: 548 548\n",
            "question, answer: 549 549\n",
            "question, answer: 550 550\n",
            "question, answer: 551 551\n",
            "question, answer: 552 552\n",
            "question, answer: 553 553\n",
            "question, answer: 554 554\n",
            "question, answer: 555 555\n",
            "question, answer: 556 555\n",
            "question, answer: 557 557\n",
            "question, answer: 558 558\n",
            "question, answer: 559 559\n",
            "question, answer: 560 560\n",
            "question, answer: 561 561\n",
            "question, answer: 562 562\n",
            "question, answer: 563 563\n",
            "question, answer: 564 564\n",
            "question, answer: 565 565\n",
            "question, answer: 566 566\n",
            "question, answer: 567 567\n",
            "question, answer: 568 568\n",
            "question, answer: 569 569\n",
            "question, answer: 570 570\n",
            "question, answer: 571 571\n",
            "question, answer: 572 572\n",
            "question, answer: 573 573\n",
            "question, answer: 574 574\n",
            "question, answer: 575 575\n",
            "question, answer: 576 576\n",
            "question, answer: 577 577\n",
            "question, answer: 578 578\n",
            "question, answer: 579 579\n",
            "question, answer: 580 580\n",
            "question, answer: 581 581\n",
            "question, answer: 582 582\n",
            "question, answer: 583 583\n",
            "question, answer: 584 584\n",
            "question, answer: 585 585\n",
            "question, answer: 586 586\n",
            "question, answer: 587 587\n",
            "question, answer: 588 588\n",
            "question, answer: 589 589\n",
            "question, answer: 590 590\n",
            "question, answer: 591 591\n",
            "question, answer: 592 592\n",
            "question, answer: 593 593\n",
            "question, answer: 594 594\n",
            "question, answer: 595 595\n",
            "question, answer: 596 596\n",
            "question, answer: 597 597\n",
            "question, answer: 598 598\n",
            "question, answer: 599 599\n",
            "question, answer: 600 600\n",
            "question, answer: 601 601\n",
            "question, answer: 602 602\n",
            "question, answer: 603 603\n",
            "question, answer: 604 604\n",
            "question, answer: 605 605\n",
            "question, answer: 606 606\n",
            "question, answer: 607 607\n",
            "question, answer: 608 608\n",
            "question, answer: 609 609\n",
            "question, answer: 610 610\n",
            "question, answer: 611 611\n",
            "question, answer: 612 612\n",
            "question, answer: 613 613\n",
            "question, answer: 614 614\n",
            "question, answer: 615 615\n",
            "question, answer: 616 616\n",
            "question, answer: 617 617\n",
            "question, answer: 618 618\n",
            "question, answer: 619 619\n",
            "question, answer: 620 620\n",
            "question, answer: 621 621\n",
            "question, answer: 622 622\n",
            "question, answer: 623 623\n",
            "question, answer: 624 624\n",
            "question, answer: 625 625\n",
            "question, answer: 626 626\n",
            "question, answer: 627 627\n",
            "question, answer: 628 628\n",
            "question, answer: 629 629\n",
            "question, answer: 630 630\n",
            "question, answer: 631 631\n",
            "question, answer: 632 632\n",
            "question, answer: 633 633\n",
            "question, answer: 634 634\n",
            "question, answer: 635 635\n",
            "question, answer: 636 636\n",
            "question, answer: 637 637\n",
            "question, answer: 638 638\n",
            "question, answer: 639 639\n",
            "question, answer: 640 640\n",
            "question, answer: 641 641\n",
            "question, answer: 642 642\n",
            "question, answer: 643 643\n",
            "question, answer: 644 644\n",
            "question, answer: 645 645\n",
            "question, answer: 646 646\n",
            "question, answer: 647 647\n",
            "question, answer: 648 648\n",
            "question, answer: 649 649\n",
            "question, answer: 650 650\n",
            "question, answer: 651 651\n",
            "question, answer: 652 652\n",
            "question, answer: 653 653\n",
            "question, answer: 654 654\n",
            "question, answer: 655 655\n",
            "question, answer: 656 656\n",
            "question, answer: 657 657\n",
            "question, answer: 658 658\n",
            "question, answer: 659 659\n",
            "question, answer: 660 660\n",
            "question, answer: 661 661\n",
            "question, answer: 662 662\n",
            "question, answer: 663 663\n",
            "question, answer: 664 664\n",
            "question, answer: 665 665\n",
            "question, answer: 666 666\n",
            "question, answer: 667 667\n",
            "question, answer: 668 668\n",
            "question, answer: 669 669\n",
            "question, answer: 670 670\n",
            "question, answer: 671 671\n",
            "question, answer: 672 672\n",
            "question, answer: 673 673\n",
            "question, answer: 674 674\n",
            "question, answer: 675 675\n",
            "question, answer: 676 676\n",
            "question, answer: 677 677\n",
            "question, answer: 678 678\n",
            "question, answer: 679 679\n",
            "question, answer: 680 680\n",
            "question, answer: 681 681\n",
            "question, answer: 682 682\n",
            "question, answer: 683 683\n",
            "question, answer: 684 684\n",
            "question, answer: 685 685\n",
            "question, answer: 686 686\n",
            "question, answer: 687 687\n",
            "question, answer: 688 688\n",
            "question, answer: 689 689\n",
            "question, answer: 690 690\n",
            "question, answer: 691 691\n",
            "question, answer: 692 692\n",
            "question, answer: 693 693\n",
            "question, answer: 694 694\n",
            "question, answer: 695 695\n",
            "question, answer: 696 696\n",
            "question, answer: 697 697\n",
            "question, answer: 698 698\n",
            "question, answer: 699 699\n",
            "question, answer: 700 700\n",
            "question, answer: 701 701\n",
            "question, answer: 702 702\n",
            "question, answer: 703 703\n",
            "question, answer: 704 704\n",
            "question, answer: 705 705\n",
            "question, answer: 706 706\n",
            "question, answer: 707 707\n",
            "question, answer: 708 708\n",
            "question, answer: 709 709\n",
            "question, answer: 710 710\n",
            "question, answer: 711 711\n",
            "question, answer: 712 712\n",
            "question, answer: 713 713\n",
            "question, answer: 714 714\n",
            "question, answer: 715 715\n",
            "question, answer: 716 716\n",
            "question, answer: 717 717\n",
            "question, answer: 718 718\n",
            "question, answer: 719 719\n",
            "question, answer: 720 720\n",
            "question, answer: 721 721\n",
            "question, answer: 722 722\n",
            "question, answer: 723 723\n",
            "question, answer: 724 724\n",
            "question, answer: 725 725\n",
            "question, answer: 726 726\n",
            "question, answer: 727 727\n",
            "question, answer: 728 728\n",
            "question, answer: 729 729\n",
            "question, answer: 730 730\n",
            "question, answer: 731 731\n",
            "question, answer: 732 732\n",
            "question, answer: 733 733\n",
            "question, answer: 734 734\n",
            "question, answer: 735 735\n",
            "question, answer: 736 736\n",
            "question, answer: 737 737\n",
            "question, answer: 738 738\n",
            "question, answer: 739 739\n",
            "question, answer: 740 740\n",
            "question, answer: 741 741\n",
            "question, answer: 742 742\n",
            "question, answer: 743 743\n",
            "question, answer: 744 744\n",
            "question, answer: 745 745\n",
            "question, answer: 746 746\n",
            "question, answer: 747 747\n",
            "question, answer: 748 748\n",
            "question, answer: 749 749\n",
            "question, answer: 750 750\n",
            "question, answer: 751 751\n",
            "question, answer: 752 752\n",
            "question, answer: 753 753\n",
            "question, answer: 754 754\n",
            "question, answer: 755 755\n",
            "question, answer: 756 756\n",
            "question, answer: 757 757\n",
            "question, answer: 758 758\n",
            "question, answer: 759 759\n",
            "question, answer: 760 760\n",
            "question, answer: 761 761\n",
            "question, answer: 762 762\n",
            "question, answer: 763 763\n",
            "question, answer: 764 764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-aecc4b8f1799>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_q_sequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mx_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev_q_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_q_sequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0msim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdev_a_sequences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mindice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"question, answer:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}